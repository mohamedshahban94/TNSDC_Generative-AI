# -*- coding: utf-8 -*-
"""Generative Adversarial Networks - Demystified!

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/generative-adversarial-networks-demystified-178187f8-5992-415c-be42-883f009338ed.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240401/auto/storage/goog4_request%26X-Goog-Date%3D20240401T160618Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D9b8275cc9541990011ffe9b555a718bf045b3204c0205ad34395a54cfe6034fbf55cae5dd26f2292d137a69f36ce904a86925cb8209258c44df2d22d288b7d87e0f5d0be198f7d4db5e3275210c0be1794389f66245e7d399f321b505a37c95337799fd86a55b432df0588596dd11fb050704a2a701abcad1ccf31630af2bfbba876210020d6f8cca955e74282d99258021839dfa2e5af1bb1ac4b7a271de9ae9a2dc2f5beab60569f3dcdf7136e22b1c262d96835878bc8178c0ae9000eb23fb2efa6fa7b25b615cc8fd0670cc533887abd77bf39382c99ecdc1317c6a17996277c254580da21e71df7e4b6cc580191914ec52e1513eda262adafe0d0cb662d
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES
# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = ':https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F11102%2F15444%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240401%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240401T160617Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D6259bb3b95b8df379b85d193796b45e0db86e1512998f0c4f88719529310cb6e49943f32761cec08b909cc0fc48f4016203f9ffaf3643a0c76da771cddf5b2e416f9206d24a8eb19e7da749f36cd1d60bbc9f4a7727323fc816910a2076e334e610dcaefc77b1466fa4f6a4dc700de1bc3bb14040d454d8a6da80c351b75dc2b67fa1b2f6a3a9e2b23cd5dd8d0c0711a8248cb6482c1fbb27241f009517bce258df298a0cb8b850fdaf9baaac3c854724a5e84336a4191329c3aaa0537f29bd8e68a22caab1136bb1057f89cfba1aeb97e4e2fd6d7b6065129fd8c4a4a9ca01e3f67d8476c303eafc3797cfb0dcbf5f1b07206bcec27031cf9c24178fbd78c3b'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

"""For those of you, who have already heard about GANs and are wondering *"What's the hype about?* should definitely go through this kernel to see the immense potential these new species of networks have.

And for those who have probably heard the name for the first time, you would be all the more amazed when you will learn about these networks.
"""

from keras.layers import Input, Dense, Reshape, Flatten, Dropout
from keras.layers import BatchNormalization, Activation, ZeroPadding2D
from keras.models import Sequential, Model
from keras.optimizers import Adam,SGD
import keras
import matplotlib.pyplot as plt
import sys
import numpy as np
import os
print(os.listdir("../input"))

from os import listdir, makedirs
from os.path import join, exists, expanduser

cache_dir = expanduser(join('~', '.keras'))
if not exists(cache_dir):
    makedirs(cache_dir)
datasets_dir = join(cache_dir, 'datasets') # /cifar-10-batches-py
if not exists(datasets_dir):
    makedirs(datasets_dir)


!cp ../input/cifar-10-python.tar.gz ~/.keras/datasets/
!ln -s  ~/.keras/datasets/cifar-10-python.tar.gz ~/.keras/datasets/cifar-10-batches-py.tar.gz
!tar xzvf ~/.keras/datasets/cifar-10-python.tar.gz -C ~/.keras/datasets/

# Load CIFAR10 data
(X_train, y_train), (_, _) = keras.datasets.cifar10.load_data()

# Select a single class images (birds)
X_train = X_train[y_train.flatten() == 2]

# Input shape
img_rows = 32
img_cols = 32
channels = 3

img_shape = (img_rows, img_cols, channels)
latent_dim = 100

"""## **The Generator**


To learn a generator distribution p<sub>g</sub> over data x,the generator builds a mapping function from a prior noise distribution p<sub>z</sub>(z) to data space as G(z). The discriminator outputs, a single scalar representing the probability that x came from training data rather than p<sub>g</sub>.

G and D are both trained simultaneously: we adjust parameters for G to minimize log(1 - D(G(z)) and adjust parameters for D to minimize logD(x), as if they are following the two-player min-max game with value function V (G;D):

![](https://github.com/Ibtastic/Generative-Adversarial-Networks/raw/master/GAN/loss.png)

* In the generator we use a method called  [Upsampling](https://towardsdatascience.com/up-sampling-with-transposed-convolution-9ae4f2df52d0) to produce images. I have used Upsampling2D but TransposeConv2d + stride or PixelShuffle could be used alternatively.


"""

def build_generator():

        model = Sequential()

        model.add(Dense(128 * 8 * 8, activation="relu", input_dim=latent_dim))
        model.add(Reshape((8, 8, 128)))

        model.add(UpSampling2D())#upsamples to 16*16*128

        model.add(Conv2D(128, kernel_size=3, padding="same"))
        model.add(BatchNormalization(momentum=0.8))
        model.add(Activation("relu"))

        model.add(UpSampling2D()) #upsamples to 32*32*128

        model.add(Conv2D(64, kernel_size=3, padding="same"))
        model.add(BatchNormalization(momentum=0.8))
        model.add(Activation("relu"))

        model.add(Conv2D(channels, kernel_size=3, padding="same"))
        model.add(Activation("tanh"))

        #outputs an image of 32*32*3

        noise = Input(shape=(latent_dim,))
        img = model(noise)

        return Model(noise, img)

def build_discriminator():

        model = Sequential()

        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding="same"))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Dropout(0.25))
        #no normalization for the first layer

        model.add(Conv2D(64, kernel_size=3, strides=2, padding="same"))
        model.add(ZeroPadding2D(padding=((0,1),(0,1))))
        model.add(BatchNormalization(momentum=0.8))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Dropout(0.25))

        model.add(Conv2D(128, kernel_size=3, strides=2, padding="same"))
        model.add(BatchNormalization(momentum=0.8))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Dropout(0.25))

        model.add(Conv2D(256, kernel_size=3, strides=1, padding="same"))
        model.add(BatchNormalization(momentum=0.8))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Dropout(0.25))

        model.add(Flatten())
        model.add(Dense(1, activation='sigmoid'))



        img = Input(shape=img_shape)
        validity = model(img)

        return Model(img, validity)

"""A lot of changes have been made in GAN's Architecture since Goodfeloow's original paper , but some things remain the same :-
* Normalizing the input
* The activation function in all except the last layer of the generator must be a relu.
* The activation in the last layer of the generator which is a Dense Layer is tanh activation.
* Same goes for the discriminator, all the layers except the last have relu as activtaion and the last Dense layer uses Sigmoid Activation.
* We use binary_cross_entropy method to calculate loss in both the adversaries.(Though in some papers like [Wasserstein gan](https://arxiv.org/pdf/1701.07875.pdf)  different loss functions is used)
"""

def show_imgs(epoch):
        r, c = 4,4
        noise = np.random.normal(0, 1, (r * c,latent_dim))
        gen_imgs = generator.predict(noise)

        # Rescale images 0 - 1
        gen_imgs = 0.5 * gen_imgs + 0.5

        fig, axs = plt.subplots(r, c)
        cnt = 0
        for i in range(r):
            for j in range(c):
                axs[i,j].imshow(gen_imgs[cnt, :,:,])
                axs[i,j].axis('off')
                cnt += 1
        plt.show()
        plt.close()

def show_losses(losses):
    losses = np.array(losses)

    fig, ax = plt.subplots()
    plt.plot(losses.T[0], label='Discriminator')
    plt.plot(losses.T[1], label='Generator')
    plt.title("Training Losses")
    plt.legend()
    plt.show()

"""Time to train the model!

Let's have a look at the original images. It will help us to compare how well our generator did. (I have only selected the bird images for training)
"""

s=X_train[:40]
s = 0.5 * s + 0.5
f, ax = plt.subplots(5,8, figsize=(16,10))
for i, img in enumerate(s):
        ax[i//8, i%8].imshow(img)
        ax[i//8, i%8].axis('off')

plt.show()

"""Some images produced by the generator after training for 30000 epochs

These images are far from perfect and can be improvised by more training or some hacks , but I think they are pretty amazing , given the fact that they are generated from nothing(random noise actually).

![](https://skymind.ai/images/wiki/GANdancers.png)
"""